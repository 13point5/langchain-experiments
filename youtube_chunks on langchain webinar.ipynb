{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first 25ish minutes of the webinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = AudioSegment.from_file(\"./data/youtube/langchain-openai-webinar-clip.mkv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(splitNumber):\n",
    "    fileId = \"langchain-webinar first split {}\".format(splitNumber)\n",
    "    return \"./data/youtube/{}.mp3\".format(fileId), \"./data/youtube/{} - Replicate x Whisper API Response.json\".format(fileId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_duration = 10\n",
    "chunk_duration_ms = chunk_duration * 60 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split_number, i in enumerate(range(0, len(audio), chunk_duration_ms)):\n",
    "# \t# Audio chunk\n",
    "# \tchunk = audio[i : i + chunk_duration_ms]\n",
    "\n",
    "# \taudioFilePath, responseFilePath = getFileNames(split_number)\n",
    "\n",
    "# \tchunk.export(audioFilePath, format=\"mp3\")\n",
    "\n",
    "# \toutput = replicate.run(\n",
    "# \t\t\"openai/whisper:91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7\",\n",
    "# \t\tinput={\"audio\": open(audioFilePath, \"rb\")}\n",
    "# \t)\n",
    "# \twith open(responseFilePath, 'w') as f:\n",
    "# \t\tjson.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "for i in range(3):\n",
    "\t_, responseFilePath = getFileNames(i)\n",
    "\toutput = json.load(open(responseFilePath, 'r'))\n",
    "\tfor segment in output['segments']:\n",
    "\t\tmoddedSegment = segment\n",
    "\t\tmoddedSegment['start'] += i * chunk_duration * 60\n",
    "\t\tmoddedSegment['end'] += i * chunk_duration * 60\n",
    "\t\tsegments.append(moddedSegment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\\n\".join([segment['text'] for segment in segments])\n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptChunks = textSplitter.create_documents([transcript])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add consecutive segments of the video as `metadata` to each chunk of the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_OVERLAP_SECONDS = 1\n",
    "chunksWithSegments = []\n",
    "\n",
    "for chunk in transcriptChunks:\n",
    "    chunkText = chunk.page_content\n",
    "\n",
    "    chunkSegments = []\n",
    "    for segment in segments:\n",
    "        if segment['text'].strip().lower() in chunkText.strip().lower():\n",
    "            chunkSegments.append(segment)\n",
    "\n",
    "    # Store consecutive segments as one segment\n",
    "    consecutiveSegments = [{\n",
    "        'start': chunkSegments[0]['start'],\n",
    "        'end': chunkSegments[0]['end']\n",
    "    }]\n",
    "\n",
    "    for segment in chunkSegments[1:]:\n",
    "        lastSegmentEnd = consecutiveSegments[-1]['end']\n",
    "\n",
    "        # range doesn't work for floats\n",
    "        if segment['start'] >= lastSegmentEnd and segment['start'] <= lastSegmentEnd + SEGMENT_OVERLAP_SECONDS:\n",
    "            consecutiveSegments[-1]['end'] = segment['end']\n",
    "        else:\n",
    "            consecutiveSegments.append({\n",
    "                'start': segment['start'],\n",
    "                'end': segment['end']\n",
    "            })\n",
    "    \n",
    "    chunksWithSegments.append(Document(\n",
    "        page_content=chunkText,\n",
    "        metadata={\n",
    "        'blockId': \"k3u46gu4bg\",\n",
    "        'segments': json.dumps(consecutiveSegments)\n",
    "        })\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"think these are some cool examples worth showing off. The first example I'll show\\n is one around maybe preventing SQL injection. Right now when we use SQL\\n agents, they kind of just output the SQL with like no escaped values. But we know\\n that to call SQL safely, we want to have template strings and we want to have\\n query parameters. So if we model this, so you know, a SQL template has a literal\\n or an identifier. There are parameters that have keys and values with a type.\" metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 1225.12, \"end\": 1255.04}]'}\n",
      "page_content=\"And the SQL query is actually a template and its parameters. And just for\\n safety, I add a is dangerous flag that determines whether or not I think or the\\n model thinks there's any kind of SQL injection. So this is all kind of just\\n modeling the data. What PyData can do is it generates the function schema\\n automatically for you. Here I just give an example of some SQL tables and then I\\n make a response. And so these are some examples I can give me, right? Give me\" metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 1255.04, \"end\": 1285.2}]'}\n"
     ]
    }
   ],
   "source": [
    "for c in chunksWithSegments:\n",
    "    if 'sql' in c.page_content.lower():\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Chroma.from_documents(documents=chunksWithSegments, embedding=OpenAIEmbeddings(), persist_directory=\"./langchain_webinar_db\")\n",
    "# db.persist()\n",
    "# db = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=\"./langchain_webinar_db\", embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-0613\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The point about SQL injection was that the speaker mentioned the importance of using template strings and query parameters to safely call SQL queries, in order to prevent SQL injection. They also mentioned that the data model they showed included a flag to determine if there was any potential for SQL injection.\n"
     ]
    }
   ],
   "source": [
    "res = qa(\"What was the point about sql injection?\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 1225.12, \"end\": 1255.04}]'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['source_documents'][0].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-experiments-R139ZWD2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
