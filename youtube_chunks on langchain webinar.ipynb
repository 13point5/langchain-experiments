{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first 25ish minutes of the webinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = AudioSegment.from_file(\"./data/youtube/langchain-openai-webinar-clip.mkv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(splitNumber):\n",
    "    fileId = \"langchain-webinar first split {}\".format(splitNumber)\n",
    "    return \"./data/youtube/{}.mp3\".format(fileId), \"./data/youtube/{} - Replicate x Whisper API Response.json\".format(fileId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_duration = 10\n",
    "# chunk_duration_ms = chunk_duration * 60 * 1000\n",
    "# for split_number, i in enumerate(range(0, len(audio), chunk_duration_ms)):\n",
    "# \t# Audio chunk\n",
    "# \tchunk = audio[i : i + chunk_duration_ms]\n",
    "\n",
    "# \taudioFilePath, responseFilePath = getFileNames(split_number)\n",
    "\n",
    "# \tchunk.export(audioFilePath, format=\"mp3\")\n",
    "\n",
    "# \toutput = replicate.run(\n",
    "# \t\t\"openai/whisper:91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7\",\n",
    "# \t\tinput={\"audio\": open(audioFilePath, \"rb\")}\n",
    "# \t)\n",
    "# \twith open(responseFilePath, 'w') as f:\n",
    "# \t\tjson.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "for i in range(3):\n",
    "\t_, responseFilePath = getFileNames(i)\n",
    "\toutput = json.load(open(responseFilePath, 'r'))\n",
    "\tsegments += output['segments']\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\\n\".join([segment['text'] for segment in segments])\n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptChunks = textSplitter.create_documents([transcript])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add consecutive segments of the video as `metadata` to each chunk of the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_OVERLAP_SECONDS = 3\n",
    "chunksWithSegments = []\n",
    "\n",
    "for chunk in transcriptChunks:\n",
    "    chunkText = chunk.page_content\n",
    "\n",
    "    chunkSegments = []\n",
    "    for segment in segments:\n",
    "        if segment['text'].strip() in chunkText:\n",
    "            chunkSegments.append(segment)\n",
    "\n",
    "    # Store consecutive segments as one segment\n",
    "    consecutiveSegments = [{\n",
    "        'start': chunkSegments[0]['start'],\n",
    "        'end': chunkSegments[0]['end']\n",
    "    }]\n",
    "\n",
    "    for segment in chunkSegments[1:]:\n",
    "        lastSegmentEnd = consecutiveSegments[-1]['end']\n",
    "\n",
    "        # range doesn't work for floats\n",
    "        if segment['start'] >= lastSegmentEnd and segment['start'] <= lastSegmentEnd + SEGMENT_OVERLAP_SECONDS:\n",
    "            consecutiveSegments[-1]['end'] = segment['end']\n",
    "        else:\n",
    "            consecutiveSegments.append({\n",
    "                'start': segment['start'],\n",
    "                'end': segment['end']\n",
    "            })\n",
    "    \n",
    "    chunksWithSegments.append(Document(\n",
    "        page_content=chunkText,\n",
    "        metadata={\n",
    "        'blockId': \"k3u46gu4bg\",\n",
    "        'segments': json.dumps(consecutiveSegments)\n",
    "        })\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Chroma.from_documents(documents=chunksWithSegments, embedding=OpenAIEmbeddings(), persist_directory=\"./langchain_webinar_db\")\n",
    "# db.persist()\n",
    "# db = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=\"./langchain_webinar_db\", embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"interact with its own inputs. And I'll show an example of doing citations.\\n These are kind of like pretty atrocious abuse of the function call API, but I\\n think these are some cool examples worth showing off. The first example I'll show\\n is one around maybe preventing SQL injection. Right now when we use SQL\\n agents, they kind of just output the SQL with like no escaped values. But we know\\n that to call SQL safely, we want to have template strings and we want to have\\n query parameters. So if we model this, so you know, a SQL template has a literal\\n or an identifier. There are parameters that have keys and values with a type.\\n And the SQL query is actually a template and its parameters. And just for\\n safety, I add a is dangerous flag that determines whether or not I think or the\\n model thinks there's any kind of SQL injection. So this is all kind of just\\n modeling the data. What PyData can do is it generates the function schema\", metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 15.76, \"end\": 75.68}]'}),\n",
       " Document(page_content=\"modeling the data. What PyData can do is it generates the function schema\\n automatically for you. Here I just give an example of some SQL tables and then I\\n make a response. And so these are some examples I can give me, right? Give me\\n the ID, give you the name for a select true, yada, yada, yada. And then when you\\n look at the examples, it does quite well, right? It escapes the right templates. It\\n uses query parameters. It'll warn me if a query is risky, but still produce a\\n query that is technically safe. So that's a fun example of sort of going away from\\n computation as a string to computation of structured data. In the second example,\\n I want to do something differently. I want to take a request that may contain\\n multiple parts and maybe search across different backends. So again, I have a\\n search type, which is a video or an email. I have a single search object, which is\\n a query and a type. I also implement the execute method, which could potentially\", metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 69.12, \"end\": 134.4}]'}),\n",
       " Document(page_content=\"but it doesn't say that he's a software developer\\n and it says that his profession is in anything.\\n So, it will work correctly.\\n And that's because we specified that it is a Boolean.\\n Again, university languages and contact.\\n Here, I said ways to contact.\\n This is quite open.\\n It's a text.\\n So, this is probably a way to catch many use cases\\n or many strings and not only one, right?\\n So, if we submit here, this is running through LangChain.\\n And here is the output.\\n So, we get the full name, the years of experience,\\n not a software developer.\\n If there's nothing specified about languages,\\n we get an empty string.\\n University and all the ways to contact the candidate.\\n So, this is a small demo of some way\\n in which this functionality might be useful for people.\\n Awesome.\\n Thanks for sharing that.\\n All right, Jason, you've been experimenting\\n from the beginning on a lot of pretty out there stuff.\\n So, I'm excited to hear what you have to share.\", metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 194, \"end\": 195.2}, {\"start\": 279.44, \"end\": 280.28000000000003}, {\"start\": 42.379999999999995, \"end\": 44.26}, {\"start\": 324.24, \"end\": 325.08}, {\"start\": 399.2, \"end\": 400.84}, {\"start\": 443.64, \"end\": 515.8199999999999}]'}),\n",
       " Document(page_content=\"hey, today we might use OpenAPI\\n but tomorrow we might use GraphQL\\n or some other like, you know, RPC language.\\n You might even want to call tools\\n that are local to the client.\\n Like, I don't know if you're building an iOS app\\n and at some point you want the language model\\n to decide to take a photo or to vibrate the phone.\\n That stuff doesn't even go over HTTP.\\n And so all of these kinds of tool integrations\\n when generalized become functions.\\n It's just, you know, call a function\\n and do something with it.\\n And so that's what took us down this path of,\\n you know, JSON schema and generalizing\\n sort of the interface.\\n And we first built plugins and trained the model on it.\\n And early days it was sort of, you know,\\n showing good life, but not quite there.\\n And in the last two, three months\\n since the plugins launch,\\n what we've done is basically\\n repeatedly fine tune the model\\n on tens of thousands of examples\\n of what good interactive tools looks like\", metadata={'blockId': 'k3u46gu4bg', 'segments': '[{\"start\": 450.36, \"end\": 501.48}]'})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"sql injection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-0613\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jason introduced himself in the conversation when he said, \"So I'm Jason. I spent the past, like maybe eight, 10 years doing things in machine learning around computer vision and recommendation systems.\"\n"
     ]
    }
   ],
   "source": [
    "res = qa(\"When did jason introduce himself?\")\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what I'm playing with right now.\n",
      " Awesome.\n",
      " Jason, do you want to do a quick intro?\n",
      " Cool, yeah.\n",
      " So I'm Jason.\n",
      " I spent the past, like maybe eight, 10 years\n",
      " doing things in machine learning\n",
      " around computer vision and recommendation systems.\n",
      " And I almost neglected natural language processing\n",
      " because I thought it was kind of like a boring subject.\n",
      " And coming back to it, I kind of regret doing that.\n",
      " And now I think language models\n",
      " are sort of like the coolest thing out there.\n",
      " So I remember playing with GBD2,\n",
      " thinking it was cool,\n",
      " then going back to my actual work.\n",
      " And now GBD4, I'm kind of like asking nicely,\n",
      " saying please, and doing everything I can\n",
      " to get the answer out.\n",
      " So it's been a fun ride.\n",
      " All right.\n",
      " Ati, do you want to go?\n",
      " Sure.\n",
      " Hi everyone.\n",
      " My name is Ati.\n",
      " I'm an engineer at OpenAI.\n",
      " I help build chat completions and function calling.\n",
      " And it's crazy to see more than a thousand people here.\n",
      " So I'm excited to share more today.\n",
      " And David.\n",
      " Hi everyone.\n",
      "[{\"start\": 191.28, \"end\": 257.40000000000003}, {\"start\": 279.44, \"end\": 280.28000000000003}, {\"start\": 42.379999999999995, \"end\": 44.26}, {\"start\": 324.24, \"end\": 325.08}, {\"start\": 503.14, \"end\": 504.41999999999996}]\n",
      "\n",
      "or David tweeting about on Twitter.\n",
      " So yeah, should be a really fun one.\n",
      " So thanks again, everyone for joining us.\n",
      " Thank you to all the panelists.\n",
      " Panelist sounds really formal.\n",
      " So, but thank you for you guys for joining.\n",
      " And maybe we can take things off with,\n",
      " actually before we do that,\n",
      " maybe quick introductions from everyone\n",
      " just to set the stage for, yeah.\n",
      " Francisco, do you want to start?\n",
      " Yeah, sure.\n",
      " So hi there.\n",
      " My name is Francisco.\n",
      " I am a data scientist.\n",
      " I'm based in Argentina.\n",
      " I worked for several years\n",
      " in a big e-commerce company here in Argentina,\n",
      " like Amazon from Latin America.\n",
      " And I am really, really fascinated with LLMs\n",
      " and the things that are being made possible.\n",
      " I've been building LLMs\n",
      " and contributing a bit to LangChain as well\n",
      " for the past few months.\n",
      " And recently I've been involved in using functions\n",
      " for tagging and extraction.\n",
      " So that's what I'm being,\n",
      " what I'm playing with right now.\n",
      " Awesome.\n",
      " Jason, do you want to do a quick intro?\n",
      "[{\"start\": 125.32000000000001, \"end\": 197.28}, {\"start\": 279.44, \"end\": 280.28000000000003}, {\"start\": 42.379999999999995, \"end\": 44.26}, {\"start\": 60.46, \"end\": 61.54}, {\"start\": 324.24, \"end\": 325.08}, {\"start\": 503.14, \"end\": 504.41999999999996}]\n",
      "\n",
      "that he's been doing.\n",
      " Then we'll go over to Jason.\n",
      " And then we'll finish up with David from ActiveLoop,\n",
      " who I will add to the stage momentarily as well.\n",
      " Then basically what we'll do is we'll go\n",
      " into question and answer.\n",
      " So there's a lot to discuss.\n",
      " There's a lot to explore.\n",
      " We really want, I think part of the excitement here\n",
      " is it's just so new and there's so many different use cases.\n",
      " So if you do have questions, please put them\n",
      " in the little question box on the right.\n",
      " It's the Q&A box.\n",
      " It's under the chat.\n",
      " It's got the question mark on it.\n",
      " You can also upvote other ones.\n",
      " So basically, after about 30, 40 minutes,\n",
      " we'll just start going through the user questions\n",
      " and answering the top ones.\n",
      " Can be anything about the functions endpoint itself.\n",
      " We're lucky to have someone from OpenAI\n",
      " who can answer that.\n",
      " Can be anything about the use cases\n",
      " that you've seen Jason or Francisco\n",
      " or David tweeting about on Twitter.\n",
      " So yeah, should be a really fun one.\n",
      "[{\"start\": 76.2, \"end\": 131.76}]\n",
      "\n",
      "So I'm excited to share more today.\n",
      " And David.\n",
      " Hi everyone.\n",
      " Sorry for running a little bit late.\n",
      " My name is David.\n",
      " I'm the founder of ActiveOp.\n",
      " Before starting the company,\n",
      " I was doing a PhD at Princeton University.\n",
      " Mostly was in computer vision space,\n",
      " but we had some projects actually building social bots\n",
      " and super excited for the last five years.\n",
      " What happened to the NLP and whole\n",
      " large language model industry, I'll say now.\n",
      " I'm super excited for this talk\n",
      " and talk about the OpenAI functions.\n",
      " Awesome.\n",
      " So let's just jump right into it.\n",
      " So Ati, take it away.\n",
      " Yeah.\n",
      " Well, I didn't prepare any slides or anything\n",
      " because I think most of you have sort of played around\n",
      " with the product and built some amazing things\n",
      " and shared them on Twitter.\n",
      " So I'll just give you a little bit of a background\n",
      " and history maybe about how this came to be,\n",
      " where we think this is going\n",
      " and why I'm personally excited about all this.\n",
      " You know, language models sort of came to shore\n",
      "[{\"start\": 194, \"end\": 195.2}, {\"start\": 238.04, \"end\": 238.88}, {\"start\": 248.8, \"end\": 305.44}, {\"start\": 40.2, \"end\": 44.26}, {\"start\": 324.24, \"end\": 325.08}, {\"start\": 503.14, \"end\": 504.41999999999996}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for source in res['source_documents']:\n",
    "\tprint(source.page_content)\n",
    "\tprint(source.metadata['segments'])\n",
    "\tprint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-experiments-R139ZWD2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
